*Skills and projects covered in LLM and ChatGPT folders*:
## *Large Language Models: Application through Production*

## LM1
Use Hugging Face datasets and large models; set up tokenizer config

## LM2
Build a **knowledge-based question answering / search system** 

 - Convert a dataset to vectors and save them in a vector library (FAISS) or database (Chroma/Pinecone/Weaviate)
 - Vectorize a query (with filters in it) and saved the output as *context*
 - Combine *context* with *original prompt* as new prompts to generate search results
 
## LM3
Build tree LLM-chain-based models
 - LLM1 moderates the comments generated by LLM2
 - Use LLM with LangChain agents (Wiki, Google, Python REPL) to do automatic data analyses
 - An LLM agent that allows user to have free chat with documents (e.g., Shakespeare's books)

## LM4
Fine-tune LLMs with Hugging Face, Tensorboard, and DeepSpeed (multiple GPU cluster support) on a traditional IMDB classification; evaluate summarization performance with NLTK and ROUGE

## LM5
Hugging Face Disaggregator (for q quick demographic analysis) and evaluate (for toxicity), gender expression generation, and SHAP (for interpretability, i.e., token-level contribution for the final generated output)

## LM6
MLOps of a sample model with mlFlow

 
## *ChatGPT_API*
- prompt engineering demos and guideline
- use of langchain, including prompt management, external agents, and evaluation tools


